{
 "metadata": {
  "name": "",
  "signature": "sha256:28a441a87067a2ac3d0b919a5b43987460779927067ad86a692a0a22936d7662"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Sentivent Project: Sentiment Analsis in Digital Journalism"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Humans tend to believe they can learn a great deal from the pages of history, the Sentivent Project is built around this very framework of understanding linguistic patterns in social writings of earlier times. In its current phase the project will be exploring the writing and reporting style of the past 75 years and contrasting them with modern form of media as it has developed today and perhaps try to learn the evolution of the form of writing and journalism. A cue that we will be using as a part of this project is public sentiment. We will be studying the differences in opinion of the people today and and the days past. We will try to build a model to recognize opinion polarity in writings of the past from learning data on modern headlines and tweets.\n",
      "\n",
      "We feel that tweets as a news-source are becoming higly relevant to society. Their reliability as a source has increased over the few years and their rate of dissemination is quickly rivaling other form of online news media. In the initial part of the project our aim is to build a supervised sentiment prediction system. Once we have optimized this system we can move onto performing regression on historic data.\n",
      "\n",
      "At this point we will try and establish that in cojugation with the SemEval 2007 initiaitive which predicts sentiment from news headlines, tweet based learners can be trained to perform just as well."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Scripts to extract training and test data from our Tweet and News Sets\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from sklearn.svm import SVR, LinearSVC\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "from sklearn.linear_model import Ridge, Lasso, LinearRegression\n",
      "from nltk.stem import WordNetLemmatizer\n",
      "from nltk import word_tokenize\n",
      "import BeautifulSoup\n",
      "from BeautifulSoup import BeautifulSoup\n",
      "\n",
      "class ShortTokenizer(object):\n",
      "    def __init__(self):\n",
      "        self.wnl = WordNetLemmatizer()\n",
      "    def __call__(self,doc):\n",
      "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc)]\n",
      "\n",
      "train_news=[]\n",
      "nclasses=[[],[],[]]\n",
      "tclasses=[[],[],[]]\n",
      "wclasses=[[],[],[]]\n",
      "soup = BeautifulSoup(open('AffectiveText.test/affectivetext_test.xml').read())\n",
      "b=soup.findAll(\"instance\")\n",
      "for i in b:\n",
      "    train_news.append(i.text)\n",
      "\n",
      "tt1 = open('AffectiveText.test/affectivetext_test.valence.gold').read().splitlines()\n",
      "for t in tt1:\n",
      "    v=int(t.split(\" \")[1])\n",
      "    if v>33:\n",
      "        nclasses[0].append(1)\n",
      "        nclasses[1].append(0)\n",
      "        nclasses[2].append(0)\n",
      "    elif v<-33:\n",
      "        nclasses[0].append(0)\n",
      "        nclasses[1].append(1)\n",
      "        nclasses[2].append(0)\n",
      "    else:\n",
      "        nclasses[0].append(0)\n",
      "        nclasses[1].append(0)\n",
      "        nclasses[2].append(1)\n",
      "\n",
      "test_news=[]\n",
      "soup = BeautifulSoup(open('AffectiveText.trial/affectivetext_trial.xml').read())\n",
      "b=soup.findAll(\"instance\")\n",
      "for i in b:\n",
      "    test_news.append(i.text)\n",
      "    ts = open('AffectiveText.trial/affectivetext_trial.valence.gold').read().splitlines()\n",
      "for t in ts:\n",
      "    v=int(t.split(\" \")[1])\n",
      "    if v>33:\n",
      "        tclasses[0].append(1)\n",
      "        tclasses[1].append(0)\n",
      "        tclasses[2].append(0)\n",
      "    elif v<-33:\n",
      "        tclasses[0].append(0)\n",
      "        tclasses[1].append(1)\n",
      "        tclasses[2].append(0)\n",
      "    else:\n",
      "        tclasses[0].append(0)\n",
      "        tclasses[1].append(0)\n",
      "        tclasses[2].append(1)\n",
      "        \n",
      "raw_news = np.array(train_news)\n",
      "raw_test = np.array(test_news)\n",
      "\n",
      "train_tweets = pd.read_csv(open('tweet_global_warming.csv'),quotechar='\"')\n",
      "raw_tweets = []\n",
      "a=train_tweets.columns[1:].tolist()\n",
      "for e in range(len(train_tweets[a[0]])):\n",
      "    v=train_tweets[a[0]][e]\n",
      "    try:\n",
      "        ind=int(train_tweets[a[1]][e])\n",
      "    except:\n",
      "        ind=0\n",
      "    if ind>0.60:\n",
      "        if v==\"No\" or v==\"N\":\n",
      "            wclasses[0].append(1)\n",
      "            wclasses[1].append(0)\n",
      "            wclasses[2].append(0)\n",
      "        elif v==\"Yes\" or v==\"Y\":\n",
      "            wclasses[0].append(0)\n",
      "            wclasses[1].append(1)\n",
      "            wclasses[2].append(0)\n",
      "        else:\n",
      "            wclasses[0].append(0)\n",
      "            wclasses[1].append(0)\n",
      "            wclasses[2].append(1)\n",
      "        raw_tweets.append(train_tweets['tweet'][e])\n",
      "        \n",
      "raw_tweets = np.array(raw_tweets)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Training and evaluation resuts for New headlines based classifiers\n",
      "pred=[[],[],[]]\n",
      "vectorizer = TfidfVectorizer (min_df=10,tokenizer=ShortTokenizer () )\n",
      "vectorizer.fit(raw_news)\n",
      "\n",
      "train_raw = raw_news.tolist()\n",
      "test_raw  = raw_test.tolist()\n",
      "X_train = vectorizer.transform(train_raw)\n",
      "X_test  = vectorizer.transform(test_raw)\n",
      "for v in range(len(nclasses)):\n",
      "    y_train = np.array(nclasses[v])\n",
      "    clf = SVR(verbose=True)\n",
      "    clf.fit(X_train,y_train)\n",
      "    pred[v] = clf.predict(X_test)\n",
      "\n",
      "from math import sqrt \n",
      "from sklearn.metrics import mean_squared_error\n",
      "for v in range(len(pred)):\n",
      "    print 1-sqrt((mean_squared_error(np.array(tclasses[v]) , np.array(pred[v])) )),"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[LibSVM][LibSVM]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[LibSVM]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.633855898024"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.496167626893 0.365367721177\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pred=[[],[],[]]\n",
      "vectorizer = TfidfVectorizer (min_df=10,tokenizer=ShortTokenizer () )\n",
      "vectorizer.fit(raw_news)\n",
      "\n",
      "train_raw = raw_news.tolist()\n",
      "test_raw  = raw_test.tolist()\n",
      "X_train = vectorizer.transform(train_raw)\n",
      "X_test  = vectorizer.transform(test_raw)\n",
      "for v in range(len(nclasses)):\n",
      "    y_train = np.array(nclasses[v])\n",
      "    clf = LinearRegression()\n",
      "    clf.fit(X_train,y_train)\n",
      "    pred[v] = clf.predict(X_test)\n",
      "\n",
      "from sklearn.metrics import mean_squared_error\n",
      "for v in range(len(pred)):\n",
      "    print 1-sqrt((mean_squared_error(np.array(tclasses[v]) , np.array(pred[v])) )),"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.619694500057 0.561740051695 0.501974513489\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pred=[[],[],[]]\n",
      "vectorizer = TfidfVectorizer (min_df=10,tokenizer=ShortTokenizer () )\n",
      "vectorizer.fit(raw_news)\n",
      "\n",
      "train_raw = raw_news.tolist()\n",
      "test_raw  = raw_test.tolist()\n",
      "X_train = vectorizer.transform(train_raw)\n",
      "X_test  = vectorizer.transform(test_raw)\n",
      "for v in range(len(nclasses)):\n",
      "    y_train = np.array(nclasses[v])\n",
      "    clf = Ridge(alpha=10)\n",
      "    clf.fit(X_train,y_train)\n",
      "    pred[v] = clf.predict(X_test)\n",
      "\n",
      "from sklearn.metrics import mean_squared_error\n",
      "for v in range(len(pred)):\n",
      "    print 1-sqrt((mean_squared_error(np.array(tclasses[v]) , np.array(pred[v])) )),"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.632009289585 0.561239129583 0.500974252503\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Training and evaluation resuts for Tweet based classifiers\n",
      "pred=[[],[],[]]\n",
      "vectorizer = TfidfVectorizer (min_df=10,tokenizer=ShortTokenizer () )\n",
      "vectorizer.fit(raw_tweets)\n",
      "\n",
      "train_raw = raw_tweets.tolist()\n",
      "test_raw  = raw_test.tolist()\n",
      "X_train = vectorizer.transform(train_raw)\n",
      "X_test  = vectorizer.transform(test_raw)\n",
      "for v in range(len(wclasses)):\n",
      "    y_train = np.array(wclasses[v])\n",
      "    clf = SVR(verbose=True)\n",
      "    clf.fit(X_train,y_train)\n",
      "    pred[v] = clf.predict(X_test)\n",
      "\n",
      "from sklearn.metrics import mean_squared_error\n",
      "for v in range(len(pred)):\n",
      "    print 1-sqrt((mean_squared_error(np.array(tclasses[v]) , np.array(pred[v])) )),"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[LibSVM][LibSVM]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[LibSVM]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.628532155052"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.271250212613 0.353523015954\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pred=[[],[],[]]\n",
      "vectorizer = TfidfVectorizer (min_df=10,tokenizer=ShortTokenizer () )\n",
      "vectorizer.fit(raw_tweets)\n",
      "\n",
      "train_raw = raw_tweets.tolist()\n",
      "test_raw  = raw_test.tolist()\n",
      "X_train = vectorizer.transform(train_raw)\n",
      "X_test  = vectorizer.transform(test_raw)\n",
      "for v in range(len(wclasses)):\n",
      "    y_train = np.array(wclasses[v])\n",
      "    clf = LinearRegression()\n",
      "    clf.fit(X_train,y_train)\n",
      "    pred[v] = clf.predict(X_test)\n",
      "\n",
      "from sklearn.metrics import mean_squared_error\n",
      "for v in range(len(pred)):\n",
      "    print 1-sqrt((mean_squared_error(np.array(tclasses[v]) , np.array(pred[v])) )),"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.606755790003 0.372479172343 0.384377561117\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pred=[[],[],[]]\n",
      "vectorizer = TfidfVectorizer (min_df=10,tokenizer=ShortTokenizer () )\n",
      "vectorizer.fit(raw_tweets)\n",
      "\n",
      "train_raw = raw_tweets.tolist()\n",
      "test_raw  = raw_test.tolist()\n",
      "X_train = vectorizer.transform(train_raw)\n",
      "X_test  = vectorizer.transform(test_raw)\n",
      "for v in range(len(wclasses)):\n",
      "    y_train = np.array(wclasses[v])\n",
      "    clf = Ridge(alpha=100)\n",
      "    clf.fit(X_train,y_train)\n",
      "    pred[v] = clf.predict(X_test)\n",
      "\n",
      "from sklearn.metrics import mean_squared_error\n",
      "for v in range(len(pred)):\n",
      "    print 1-sqrt((mean_squared_error(np.array(tclasses[v]) , np.array(pred[v])) )),"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.632930885534 0.454538069988 0.429272976864\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}